{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hardware</th>\n",
       "      <th>prompt_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>average_power</th>\n",
       "      <th>prompt_time</th>\n",
       "      <th>token_time</th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>tensor_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama2-70b</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>196.253219</td>\n",
       "      <td>54.879512</td>\n",
       "      <td>7168.983698</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2-70b</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>195.561664</td>\n",
       "      <td>54.856293</td>\n",
       "      <td>7165.270329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama2-70b</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>197.440176</td>\n",
       "      <td>54.804960</td>\n",
       "      <td>7160.753250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama2-70b</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>196.862379</td>\n",
       "      <td>54.856482</td>\n",
       "      <td>7166.614532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama2-70b</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>197.144004</td>\n",
       "      <td>54.812980</td>\n",
       "      <td>7161.341190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   hardware  prompt_size  batch_size  token_size  peak_power  \\\n",
       "0  llama2-70b  a100-80gb          512           1         128    1.000012   \n",
       "1  llama2-70b  a100-80gb          512           1         128    1.000012   \n",
       "2  llama2-70b  a100-80gb          512           1         128    1.000012   \n",
       "3  llama2-70b  a100-80gb          512           1         128    1.000012   \n",
       "4  llama2-70b  a100-80gb          512           1         128    1.000012   \n",
       "\n",
       "   average_power  prompt_time  token_time     e2e_time  tensor_parallel  \n",
       "0       0.735994   196.253219   54.879512  7168.983698                2  \n",
       "1       0.735994   195.561664   54.856293  7165.270329                2  \n",
       "2       0.735994   197.440176   54.804960  7160.753250                2  \n",
       "3       0.735994   196.862379   54.856482  7166.614532                2  \n",
       "4       0.735994   197.144004   54.812980  7161.341190                2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"../data/perf_model.csv\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_llama270b_and_bloom176b(x):\n",
    "    if x == \"llama2-70b\":\n",
    "        return \"A\"\n",
    "    return \"B\"\n",
    "df_1[\"model\"] = df_1[\"model\"].apply(convert_llama270b_and_bloom176b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.append(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hardware</th>\n",
       "      <th>prompt_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>average_power</th>\n",
       "      <th>prompt_time</th>\n",
       "      <th>token_time</th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>tensor_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026356</td>\n",
       "      <td>1.091423</td>\n",
       "      <td>1.120188</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>1.088581</td>\n",
       "      <td>1.115339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>1.087884</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.089089</td>\n",
       "      <td>1.113870</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>1.087631</td>\n",
       "      <td>1.112059</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   hardware  prompt_size  batch_size  token_size  peak_power  \\\n",
       "0  Llama-3.1-8B  a100-80gb          128           1         128           0   \n",
       "1  Llama-3.1-8B  a100-80gb          128           1         128           0   \n",
       "2  Llama-3.1-8B  a100-80gb          128           1         128           0   \n",
       "3  Llama-3.1-8B  a100-80gb          128           1         128           0   \n",
       "4  Llama-3.1-8B  a100-80gb          128           1         128           0   \n",
       "\n",
       "   average_power  prompt_time  token_time  e2e_time  tensor_parallel  \n",
       "0              0     0.026356    1.091423  1.120188                2  \n",
       "1              0     0.024628    1.088581  1.115339                2  \n",
       "2              0     0.024099    1.087884  1.114281                2  \n",
       "3              0     0.022691    1.089089  1.113870                2  \n",
       "4              0     0.022682    1.087631  1.112059                2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.concat([pd.read_csv(\"../data/Llama-3.1-8B-tp-2.csv\"), pd.read_csv(\"../data/Llama-3.1-8B-tp-4.csv\")])\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2[\"model\"] = \"C\"\n",
    "df_2[\"tensor_parallel\"] = df_2[\"tensor_parallel\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hardware</th>\n",
       "      <th>prompt_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>average_power</th>\n",
       "      <th>prompt_time</th>\n",
       "      <th>token_time</th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>tensor_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026356</td>\n",
       "      <td>1.091423</td>\n",
       "      <td>1.120188</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>1.088581</td>\n",
       "      <td>1.115339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>1.087884</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.089089</td>\n",
       "      <td>1.113870</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>1.087631</td>\n",
       "      <td>1.112059</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model   hardware  prompt_size  batch_size  token_size  peak_power  \\\n",
       "0     C  a100-80gb          128           1         128           0   \n",
       "1     C  a100-80gb          128           1         128           0   \n",
       "2     C  a100-80gb          128           1         128           0   \n",
       "3     C  a100-80gb          128           1         128           0   \n",
       "4     C  a100-80gb          128           1         128           0   \n",
       "\n",
       "   average_power  prompt_time  token_time  e2e_time  tensor_parallel  \n",
       "0              0     0.026356    1.091423  1.120188                4  \n",
       "1              0     0.024628    1.088581  1.115339                4  \n",
       "2              0     0.024099    1.087884  1.114281                4  \n",
       "3              0     0.022691    1.089089  1.113870                4  \n",
       "4              0     0.022682    1.087631  1.112059                4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.append(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([pd.read_csv(\"../data/Llama-3.2-3B-tp-2.csv\"), pd.read_csv(\"../data/Llama-3.2-3B-tp-4.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hardware</th>\n",
       "      <th>prompt_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>average_power</th>\n",
       "      <th>prompt_time</th>\n",
       "      <th>token_time</th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>tensor_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.693438</td>\n",
       "      <td>0.720412</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020426</td>\n",
       "      <td>0.693831</td>\n",
       "      <td>0.716382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.691959</td>\n",
       "      <td>0.714792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.696073</td>\n",
       "      <td>0.718119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.691251</td>\n",
       "      <td>0.714097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   hardware  prompt_size  batch_size  token_size  peak_power  \\\n",
       "0  Llama-3.2-3B  a100-80gb          128           1         128           0   \n",
       "1  Llama-3.2-3B  a100-80gb          128           1         128           0   \n",
       "2  Llama-3.2-3B  a100-80gb          128           1         128           0   \n",
       "3  Llama-3.2-3B  a100-80gb          128           1         128           0   \n",
       "4  Llama-3.2-3B  a100-80gb          128           1         128           0   \n",
       "\n",
       "   average_power  prompt_time  token_time  e2e_time  tensor_parallel  \n",
       "0              0     0.024418    0.693438  0.720412                2  \n",
       "1              0     0.020426    0.693831  0.716382                2  \n",
       "2              0     0.020986    0.691959  0.714792                2  \n",
       "3              0     0.020099    0.696073  0.718119                2  \n",
       "4              0     0.020796    0.691251  0.714097                2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3[\"model\"] = \"D\"\n",
    "df_3[\"tensor_parallel\"] = df_3[\"tensor_parallel\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.append(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hardware</th>\n",
       "      <th>prompt_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>average_power</th>\n",
       "      <th>prompt_time</th>\n",
       "      <th>token_time</th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>tensor_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>196.253219</td>\n",
       "      <td>54.879512</td>\n",
       "      <td>7168.983698</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>195.561664</td>\n",
       "      <td>54.856293</td>\n",
       "      <td>7165.270329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>197.440176</td>\n",
       "      <td>54.804960</td>\n",
       "      <td>7160.753250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>196.862379</td>\n",
       "      <td>54.856482</td>\n",
       "      <td>7166.614532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>a100-80gb</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>197.144004</td>\n",
       "      <td>54.812980</td>\n",
       "      <td>7161.341190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model   hardware  prompt_size  batch_size  token_size  peak_power  \\\n",
       "0     A  a100-80gb          512           1         128    1.000012   \n",
       "1     A  a100-80gb          512           1         128    1.000012   \n",
       "2     A  a100-80gb          512           1         128    1.000012   \n",
       "3     A  a100-80gb          512           1         128    1.000012   \n",
       "4     A  a100-80gb          512           1         128    1.000012   \n",
       "\n",
       "   average_power  prompt_time  token_time     e2e_time  tensor_parallel  \n",
       "0       0.735994   196.253219   54.879512  7168.983698                2  \n",
       "1       0.735994   195.561664   54.856293  7165.270329                2  \n",
       "2       0.735994   197.440176   54.804960  7160.753250                2  \n",
       "3       0.735994   196.862379   54.856482  7166.614532                2  \n",
       "4       0.735994   197.144004   54.812980  7161.341190                2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../data/perf_model_4_models.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
